# Pipeline de dados

Neste projeto foi abordado a seguinte situa√ß√£o: Duas empresas se unificaram e agora precisam dos dados da empresaA e empresaB unidos. Por√©m, esses dados n√£o est√£o no formato esperado e por isso foi criado este pipeline para extrair, tratar e carregar os dados. O famoso ETL.

## Cria√ß√£o das pastas da pipeline em um WSL

Esse processo foi crucial para colocarmos em pauta onde ser√£o alocados as pastas e arquivos que estaremos trabalhando. Dessa forma, foi pensando em colocar em WSL (Windows Subsystem for Linux). Que √© um subsistema do Linux no Windows onde estarei manipulando estes arquivos e criando pastas para organizar todo o projeto.

## Rodando o VSCode no nosso ambiente virtual

Na imagem abaixo, estamos chamando o 'dir' para listarmos as pastas criadas nesse caminho. Como j√° temos uma pasta "Documentos" criada, onde ficar√° os arquivos do nosso projeto, n√£o ser√° necess√°rio utilizar o comando 'mkdir' para a cria√ß√£o da pasta para alocar os nosso arquivos.

![image](https://github.com/user-attachments/assets/bba89692-90c4-4d9b-bb83-ccd61e95be11)

## Explorando os dados no Jupyter Notebook

Ap√≥s montarmos o ambiente e construir as pastas no diret√≥rio informado, realizamos a explora√ß√£o dos dados com o Jupyter Notebook e assim fazemos toda a an√°lise dos dados que est√£o sendo coletados nos arquivos .JSON e .CSV. Verificamos ali a quantidade de linhas em cada arquivo, cada Header (cabe√ßalho) dos arquivos e imprimindo os dados que cont√©m neles.

Como o tipo do arquivo .CSV √© um tipo lista n√≥s precisamos deixar os arquivo .JSON neste mesmo padr√£o para que conseguissemos unir estes dados. Com isso, foi feito todo tratamento dos dados .JSON, assim como a nomenclatura das colunas para unificarmos esses dados. Na vari√°vel KeyMapping, foi poss√≠vel fazer um de para das chaves que estavam listadas no arquivo, para que ficasse igual ao nosso .CSV.

H√° um ponto se frisar, que nos nossos dados do arquivo .JSON n√£o temos a chave 'Data da venda' como temos no arquivo .CSV. Por√©m, iremos incluir essa chave dentro do nosso arquivo de fus√£o e substituindo os valores em branco pela palavra "Indisponivel" para que assim possa ser demonstrado que essa coluna receber√° os dados futuramente pelo departamento respons√°vel.

![image](https://github.com/user-attachments/assets/6618ea7d-0f35-4e5b-a62b-7adeb0182b3e)

## Montando o nosso Script

### Script das fus√µes dos dados

Explorando os dados e entendendo como eles se comportam no nosso Notebook, agora est√° na hora de criarmos o nosso Script para os outros tratamentos que iremos realizar futuramente. Nesta primeira etapa j√° estamos fazendo a extra√ß√£o dos dados de ambos os arquivos, renomeando as nossas colunas e unindo estes dados. Importamos a nossso "processamento_dados" e atribu√≠ndo a classe "dados" em nosso arquivo principal para que possamos classificarmos por met√≥dos e atributos.

![image](https://github.com/user-attachments/assets/9cac1ac3-bc2e-4cc1-82f8-52e32c1a24b0)


### Sript do processamento dos dados

Nesta parte, estaremos classificando todo o tratamento dos dados dos dois arquivos pelo processo de atributos nesse m√©todo privado expl√≠cito em nosso c√≥digo. Dentro dessa classe "dados" temos v√°rias fun√ß√µes fazendo esse processamento. Uma delas √© o tratamento das colunas com o List Comprehension que √© muito utilizado para diminuir o tamanho do c√≥digo que poderia ser utilizado, para ser mais eficiente que um for, por exemplo.

Ap√≥s criarmos toda essa leitura e tratamento dos dados, iremos unir l√° no final do c√≥digo e salvar estes dados l√° na √∫ltima fun√ß√£o criada dentro dessa classe. Isso est√° demonstrado na imagem 2 desse projeto. Assim, finalizando todo o tratamento dos dados e salvando em uma pasta chamada "data_processed". Esse arquivo ficar√° no tipo .CSV mesmo, como se trata de uma lista.

### Imagem 1:

![image](https://github.com/user-attachments/assets/ca1a339b-9f1a-4cdd-8071-ee2a318a6234)

### Imagem 2:

![image](https://github.com/user-attachments/assets/69faf4b2-92b0-43b8-b91a-c179e59f0230)

## Os dados tratados

Sei que por aqui ficar√° meio complicado de visualizar o resultado final dess projeto, por√©m n√£o poderia deixar de concluir ele demonstrando como fico esses dados dentro do nosso arquivo. Nesta primeira imagem, estar√° os dados .JSON que n√£o cont√©m os dados da chave "Data da Venda". Assim, ela ficou substitu√≠da conforme na imagem 1.

Em seguida na imagem 2, temos os dados .CSV que ficaram no final dessa jun√ß√£o dos dados. Nela teremos todos os dados completos, assim como a data da venda que n√£o tinhamos no .JSON.

### Imagem 1:

![image](https://github.com/user-attachments/assets/3a24cfb1-058e-4b1e-acfb-986edd578e72)

### Imagem 2:

![image](https://github.com/user-attachments/assets/c0ca5016-b333-40de-b518-ad515b9680b4)

## Conclus√£o

Fiquei muito contente em aprimorar minhas habilidades com o tratamento de dados com Python. Esse projeto foi uma grande proje√ß√£o de que ainda n√£o acabou e que os estudos dever√£o continuar para aprimorar o racioc√≠nio e melhorar o desempenho do c√≥digo a partir das dificuldades apresentadas em nosso dia-a-dias.

Obrigado pela visita! üòâ
